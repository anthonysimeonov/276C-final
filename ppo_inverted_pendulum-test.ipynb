{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import my_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Process Process-14:\n",
      "Process Process-8:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-9:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-7:\n",
      "Process Process-16:\n",
      "Process Process-5:\n",
      "Process Process-13:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"InvertedPendulum-v2\"\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 64\n",
    "lr               = 3e-4\n",
    "num_steps        = 2048\n",
    "mini_batch_size  = 64\n",
    "ppo_epochs       = 10\n",
    "threshold_reward = 950\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "weights = torch.load('InvertedPendulum_PPO.pt')\n",
    "model.load_state_dict(weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 1000000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fdc7486d0ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7e55721e6f86>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anthony/pytorch_0.4/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anthony/pytorch_0.4/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
