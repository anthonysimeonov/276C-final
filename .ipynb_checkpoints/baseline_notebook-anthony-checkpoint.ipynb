{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import my_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-15:\n",
      "Process Process-14:\n",
      "Process Process-13:\n",
      "Process Process-8:\n",
      "Process Process-16:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "Process Process-7:\n",
      "Process Process-11:\n",
      "Process Process-9:\n",
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/arclabdl2/ECE276C_project/276C-final/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "# env_name = \"HalfCheetah-v2\"\n",
    "# env_name = \"FetchReach-v1\"\n",
    "# env_name = \"Humanoid-v2\"\n",
    "env_name = 'InvertedPendulumModified-friction-v10'\n",
    "# env_name = 'ReacherSpringy-v1'\n",
    "\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value\n",
    "    \n",
    "class ActorCriticComp(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCriticComp, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "def test_env_comp(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        dist_comp, _ = compensator(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0] + dist_comp.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "#             dist, value = model(state)\n",
    "            dist, value = compensator(state)\n",
    "\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 64\n",
    "lr               = 3e-4\n",
    "num_steps        = 2048\n",
    "mini_batch_size  = 64\n",
    "ppo_epochs       = 10\n",
    "threshold_reward = 950\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "weights = torch.load('unmodified_weights/InvertedPendulumBase_PPO.pt')\n",
    "model.load_state_dict(weights)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "comp_hidden_size = 64\n",
    "compensator = ActorCriticComp(num_inputs, num_outputs, comp_hidden_size).to(device)\n",
    "optimizer = optim.Adam(compensator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 1000000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a67b6f43f4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#     ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3658b703aa2c>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anthony/pytorch_0.4/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anthony/pytorch_0.4/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    log_probs_comp = []\n",
    "    values    = []\n",
    "    values_comp = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    actions_comp = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "    entropy_comp = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        \n",
    "        dist, value = model(state)\n",
    "        dist_comp, value_comp = compensator(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_comp = dist_comp.sample()\n",
    "        \n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy() + action_comp.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        log_prob_comp = dist_comp.log_prob(action_comp)\n",
    "        \n",
    "        entropy += dist.entropy().mean()\n",
    "        entropy_comp += dist_comp.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        log_probs_comp.append(log_prob_comp)\n",
    "        \n",
    "        values.append(value)\n",
    "        values_comp.append(value_comp)\n",
    "        \n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        \n",
    "        actions.append(action)\n",
    "        actions_comp.append(action_comp)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env_comp() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "#     _, next_value = model(next_state)\n",
    "    _, next_value_comp = compensator(next_state)\n",
    "    returns = compute_gae(next_value_comp, rewards, masks, values_comp)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    log_probs_comp = torch.cat(log_probs_comp).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    values_comp = torch.cat(values_comp).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    actions_comp = torch.cat(actions_comp)\n",
    "    advantage = returns - values_comp\n",
    "    \n",
    "#     ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)\n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions_comp, log_probs_comp, returns, advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
