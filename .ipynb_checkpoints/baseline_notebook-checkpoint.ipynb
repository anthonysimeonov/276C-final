{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import my_envs\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "# env_name = \"HalfCheetahModified-leg-v0\"\n",
    "# env_name = \"FetchReach-v1\"\n",
    "# env_name = \"Humanoid-v2\"\n",
    "#env_name = 'InvertedPendulum-v2'\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 64\n",
    "lr               = 3e-4\n",
    "num_steps        = 2048\n",
    "mini_batch_size  = 64\n",
    "ppo_epochs       = 10\n",
    "threshold_reward = 1500\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 1000000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env() for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    advantage = returns - values\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_0.4]",
   "language": "python",
   "name": "conda-env-pytorch_0.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
